# Bagging Example on Car Data


# Bagging stands for Boostrap Aggregating
# We want to build a lot of different base learners on bootstrapped samples of the data
# and we combine their predictions, like doing a big average of the different results.
# It helps to reduce variance and avoid overfitting .

# Bagging works best for base learner with low bias and high variance like
# deep decision trees.

# However, a downside of bagging is that dominant features can cause trees to have a 
# similar structure. This phenom is called "tree correlation".
# Bagging gets its predictive performance from variance reduction,
# but this reduction decrease when the tree correlation increase.
# Therefore, dominant feature impact negatively the predictive performance
# of a bagged ensemble

# Random Forest counter this problem by averaging an ensemble of de-correlated trees.

# Before each split, select a subset of features at random as candidate features for splitting
# This essentially decorrelates the trees in the ensemble, improving predictive performance
# The number of candidates is typically considered a tuning parameter
# Random forest introduces randomness in the rows and columns of the data


# Define columnn class for dataset
colCls <- c("integer",         # row id
            "character",       # analysis year
            "numeric",         # exposure
            "character",       # new business / renewal business
            "numeric",         # driver age (continuous)
            "character",       # driver age (categorical)
            "character",       # driver gender
            "character",       # marital status
            "numeric",         # years licensed (continuous)
            "character",       # years licensed (categorical)
            "character",       # ncd level
            "character",       # region
            "character",       # body code
            "numeric",         # vehicle age (continuous)
            "character",       # vehicle age (categorical)
            "numeric",         # vehicle value
            "character",       # seats
            rep("numeric", 6), # ccm, hp, weight, length, width, height (all continuous)
            "character",       # fuel type
            rep("numeric", 3)  # prior claims, claim count, claim incurred (all continuous)
)


# Define the data path and filename
data.path <- "C:\\Users\\William.Tiritilli\\Documents\\Project P\\Frees\\Tome 2 - Chapter 1\\"
data.fn <- "sim-modeling-dataset2.csv"

# Read in the data with the appropriate column classes
dta <- read.csv(paste(data.path, data.fn, sep = "/"),
                colClasses = colCls)
str(dta)

# Define a train and test set
set.seed(54321) # reproducubility
# Create a stratified data partition
train_id <- caret::createDataPartition(
  y = dta$clm.count/dta$exposure,
  p = 0.8,
  groups = 100
)[[1]]


# Divide the data in training and test set
dta_trn <- dta[train_id,]
dta_tst <- dta[-train_id,]


library(dplyr)
# Proportions of the number of claims in train data
dta_trn$clm.count %>% table %>% prop.table %>% round(5)
# Proportions of the number of claims in test data
dta_tst$clm.count %>% table %>% prop.table %>% round(5)



# Other elements for EDA
library(ggplot2)

# Next, we also model claim severity, i.e., the expected loss amount for a claim if it gets filed. 
# The variable `amount` in `mtpl_data` contains the total loss amount over all claims filed by a policyholder. 
# In order to get an estimate of the individual claim severity, the variable `average` contains the total loss amount divided by the number of claims. 
# Only the observations containing a claim can be used to model claim severity:
  

# Only retain the claims
dta_trn_claims <- dta_trn %>% dplyr::filter(clm.count > 0)

# Graphs
gridExtra::grid.arrange(
  ggplot(dta_trn_claims, aes(x = clm.incurred/clm.count)) + 
    geom_density(adjust = 3, col = 'black', fill = 'gray') +
    labs(y = 'Density'),
  ggplot(dta_trn_claims, aes(x = clm.incurred/clm.count)) + 
    geom_density(adjust = 3, col = 'black', fill = 'gray') +
    labs(y = 'Density') + xlim(0, 1e4),
  ncol = 2
)





# Tuning Strategy

# Many tuning parameters in a random forest:
#   number of trees
#   number of candidates for splitting
#   max tree depth
#   minimun leaf node size
#   sample fraction


# To track our results, we set up a full Cartesian grid via expand.grid :
 search_grid <- expand.grid(
  num.trees = c(100,200),
  mtry = c(3,5,7), # Carefull: cannot be > nb of variables in date
  min.node.size = c(0.001,0.01)*nrow(dta),
  error = NA
)

print(search_grid)



# We perform the grid search and track the OOB error
# For that, we use function {ranger}

library(ranger)

for(i in seq_len(nrow(search_grid))) {
  # fit a random forest for the ith combination
  fit <- ranger(
    formula = clm.count ~
      driver.age + yrs.licensed + ccm + hp + 
       fuel.type + driver.gender + nb.rb, 
    
    data = dta_trn, 
    num.trees = search_grid$num.trees[i],
    mtry = search_grid$mtry[i],
    min.node.size = search_grid$min.node.size[i],
    replace = TRUE,
    sample.fraction = 0.75,
    verbose = FALSE,
    seed = 54321
  
    )
  # get the OOB error 
  search_grid$error[i] <- fit$prediction.error
}

# Results
search_grid %>% arrange(error)


# The usual package only support standard regression based on the Mean Square Error.

# The solution: {distRforest} 
# based on {rpart} which supports Poisson regression (as we have seen before)
# extended to support Gamma and log-normal deviance as loss function
# extended to support random forest generation
# this package is used in Henckaerts et al. (2019, arXiv)

# devtools::install_github('henckr/distRforest')
library(distRforest)
library(rpart)

# ?rforest

# Original code show 'redem''instead of 'red_mem
set.seed(54321) # reproducibility
fit_rf <- rforest(
  formula = cbind(exposure,clm.count) ~
    driver.age + yrs.licensed + ccm + hp + 
    fuel.type + driver.gender + nb.rb,
  
  data = dta_trn,
  method = 'poisson',
  control = rpart.control( # list of options that control the fitting details of the rpart trees.
    maxdepth = 20,
    minsplit = 2000,
    minbucket = 1000,
    cp = 0,
    xval = 0
  ),
  
  ntrees = 100,
  ncand = 5,
  subsample = 0.75,
  # track_oob = TRUE,
  red_mem = TRUE # Carefull, put the redmem in the rpart.control function
  
)

class(fit_rf)
class(fit_rf[[1]])

# Get vi of each individual tree
var_imps <- lapply(fit_rf, vip::vi)
# Still retrieve an error


# With another code
features <- c('driver.age' , 'yrs.licensed', 'ccm', 'hp', 
                'fuel.type', 'driver.gender', 'nb.rb')

set.seed(54321)
rf_freq <- distRforest::rforest(
  formula = as.formula(paste('cbind(exposure, clm.count) ~', paste(features, collapse = ' + '))),
  data = dta_trn,
  method = 'poisson',
  ntrees = 100, # T in Table 3
  ncand = 5, # m in Table 3
  subsample = 0.75, # delta in Table 1
  parms = list(shrink = 0.25), # gamma in Table 1
  control = rpart.control(cp = 0, # cp in Table 1
                          # Minbucket = 0.01 * 0.75 * nrow(mtpl_trn),
                          # Was creating an error here, bc the calculation was
                          # retrieving a decimal number
                          minbucket = 300, # kappa * delta in Table 1
                          xval = 0,
                          maxcompete = 0,
                          maxsurrogate = 0),
  track_oob = TRUE, # parameter to track the OOB evolution
  red_mem = TRUE # reduces the memory footprint of individual rpart trees
)

class(rf_freq)

# Only retain the claims
dta_trn_claims <- dta_trn %>% dplyr::filter(clm.count > 0)
# Plot the density of all observations and those below 10 000 Euro
gridExtra::grid.arrange(
  ggplot(dta_trn_claims, aes(x = clm.incurred)) + 
    geom_density(adjust = 3, col = 'black', fill = 'gray') +
    labs(y = 'Density'),
  ggplot(dta_trn_claims, aes(x = clm.incurred)) + 
    geom_density(adjust = 3, col = 'black', fill = 'gray') +
    labs(y = 'Density') + xlim(0, 1e4),
  ncol = 2
)


### Random forest

# We fit a gamma random forest for claim severity with the `rforest()` function and `method = 'gamma'` from the `distRforest` package 
#          (available from Roel Henckaerts's [GitHub](https://github.com/henckr/distRforest)):

set.seed(54321)
rf_sev <- distRforest::rforest(
  formula = as.formula(paste('clm.incurred ~', paste(features, collapse = ' + '))),
  data = dta_trn_claims,
  weights = clm.count,
  method = 'gamma',
  ntrees = 600, # T in Table 3
  ncand = 1, # m in Table 3
  subsample = 0.75, # delta in Table 1
  control = rpart.control(cp = 0, # cp in Table 1
                          minbucket = 0.01 * 0.75 * nrow(dta_trn_claims), # kappa * delta in Table 1
                          xval = 0,
                          maxcompete = 0,
                          maxsurrogate = 0),
  red_mem = TRUE # reduces the memory footprint of individual rpart trees
)


# Generic prediction function
predict_model <- function(object, newdata) UseMethod('predict_model')

# Prediction function for a random forest
predict_model.rforest <- function(object, newdata) {
  predict(object, newdata)
}


var_imp <- function(object) {
  # Calculate non-normalized importance scores based on the model class
  switch(class(object)[1]
,
         
         'rforest' = object %>% distRforest::importance_rforest() %>% 
           dplyr::select(variable, importance)
         

  ) %>% 
    # Normalize the scores to sum to one
    dplyr::mutate(scale_sum = round(importance / sum(importance), digits = 4))
}

plot_var_imp <- function(data) {
  data %>% ggplot(aes(x = reorder(variable, scale_sum), y = scale_sum)) + 
    geom_bar(stat = 'identity') + coord_flip() + 
    labs(x = '', y = 'importance')
}

# Frequency
gridExtra::grid.arrange(#tree_freq %>% var_imp %>% plot_var_imp,
                        rf_freq %>% var_imp %>% plot_var_imp,
                        #gbm_freq %>% var_imp %>% plot_var_imp,
                        ncol = 3)


#The variable importance scores for the three severity ML models are shown below. 
#These are the green bars for data fold 3 in the right panels of Figure 5 in the paper.

# Severity
gridExtra::grid.arrange(#tree_sev %>% var_imp %>% plot_var_imp,
                        rf_sev %>% var_imp %>% plot_var_imp,
                        #gbm_sev %>% var_imp %>% plot_var_imp,
                        ncol = 3)



### PDPs
#We use partial dependence plots (PDPs) to get an insight on the relation between a feature and the target. 
#The function `par_dep` performs the essential steps to generate such a PD effect. 
#The following steps are performed for each value in a predefined grid of the variable of interest:

# + use the original training data (or a subset to speedup calculations)
# + change the value of the variable of interest to the current value in the grid for all observations
# + predict the model on this altered data set
# + calculate the mean of all these predictions to get the PD effect for the current grid value


# modififaction of the par_dep function for the RF
par_dep_rf <- function(object, data, grid) {
  # Initialize a vector to save the effect
  pd_effect <- rep(0, nrow(grid))
  # Iterate over the grid values to calculate the effect
  for (i in seq_len(length(pd_effect))) {
    pd_effect[i] <- 
      data %>% 
      dplyr::mutate(!! names(grid) := grid[i, ]) %>% 
      distRforest::predict.rforest(object, newdata = .) %>% # specific to RF
      mean()
  }
  return(pd_effect)
}


# Generic prediction function
predict_model <- function(object, newdata) UseMethod('predict_model')

# Prediction function for a random forest
predict_model.rforest <- function(object, newdata) {
  predict(object, newdata)
}



# Use a random sample of the training observations
set.seed(54321)
dta_trn_sample <- dta_trn[sample(seq_len(nrow(dta_trn)), size = 10000), ]
# Define the grid for the ages
grid_ageph <- data.frame('driver.age' = 18:90)
# Calculate the PD effect for each ML model
# grid_ageph <- grid_ageph %>% 
#   dplyr::mutate(#tree = rpart.fit %>% par_dep(data = dta_trn_sample,
#                                              #grid = grid_ageph))

grid_ageph <- grid_ageph %>% 
      dplyr::mutate(
                    rf = rf_freq %>% par_dep_rf(data = dta_trn_sample,
                                             grid = grid_ageph))

#After some reshaping we can plot these effects on top of each other. 
#The effects for the tree and the gbm correspond to the green lines in the bottom panels of Figure 6.

grid_ageph %>% reshape2::melt(id.vars = 'driver.age',
                              value.name = 'pd',
                              variable.name = 'method') %>% 
  ggplot(aes(x = driver.age, y = pd)) + 
  geom_line(aes(group = method, colour = method))


# Observe each of the individual tree

# For more information
# https://henckr.github.io/distRforest/articles/distRforest.html

rf_freq[['trees']][[1]]



# Analysis of the evoluation of the OOB Error
oob_df <- data.frame('iteration' = seq_len(length(rf_freq[['oob_error']])),
                     'oob_error' = rf_freq[['oob_error']])


library(ggplot2)
ggplot(oob_df, aes(x = iteration, y = oob_error)) + geom_point()


# The OOB error evolution (track_oob = TRUE in rforest) 
# shows a decreasing trend in the Poisson deviance, 
# which means that the predictions for the claim numbers are improving 
# over the iterations:


# Get vi of each individual tree
# The below does not work
# var_imps <- lapply(rf_freq, vip::vi)
# 
# distRforest::importance_rforest() %>% 
#   dplyr::select(variable, importance)

# The Variable Importance analysis can be done on the total forest, not on an individual tree
# The VI is of the improvements in the loss function over all the splits on that variable.
# The idea is that important variable appear often and high in the decision tree such
# that the sum grows largest doe those variables.

var_imps <- rf_freq %>% importance_rforest

# On a graph
var_imps %>% 
  group_by(variable) %>% 
  summarise(importance = mean(importance)) %>% 
  arrange(-importance) %>% 
  ggplot(aes(x = reorder(variable,importance), y = importance/max(importance))) + 
  geom_bar(stat = 'identity') + coord_flip() + labs(x = 'Variable')





### ICEs
# An individual conditional expectation (ICE) curve is generated in a very comparable way to a PDP. 
# The same steps as listed above are followed, only the last step is not performed. 
# An ICE curve shows the individual predictions instead of averaging all the predictions (like in a PDP). 
# The function `ice` to generate an ICE curve is therefore very similar to `par_dep`:


ice <- function(object, data, grid) {
  # Initialize a matrix to save the effect
  ice_effect <- matrix(0, nrow = nrow(grid), ncol = nrow(data))
  # Iterate over the grid values to calculate the effect
  for (i in seq_len(nrow(ice_effect))) {
    ice_effect[i, ] <- 
      data %>% 
      dplyr::mutate(!! names(grid) := grid[i, ]) %>% 
      predict_model(object, newdata = .)
  }
  return(cbind(grid, ice_effect))
}

ice_rf <- function(object, data, grid) {
  # Initialize a matrix to save the effect
  ice_effect <- matrix(0, nrow = nrow(grid), ncol = nrow(data))
  # Iterate over the grid values to calculate the effect
  for (i in seq_len(nrow(ice_effect))) {
    ice_effect[i, ] <- 
      data %>% 
      dplyr::mutate(!! names(grid) := grid[i, ]) %>% 
      distRforest::predict.rforest(object, newdata = .)
  }
  return(cbind(grid, ice_effect))
}



#We will now use this function to generate the ICE effect for 
# the bonus-malus level in frequency models:

# Use a random sample of the training observations
set.seed(54321)
dta_trn_sample <- dta_trn[sample(seq_len(nrow(dta_trn)), size = 1000), ]
# Define the grid for the ages
grid_hp <- data.frame('hp' = 0:200)
# Calculate the ICE effect

# Still the same error
# no applicable method for 'predict_model' applied to an object of class "rpart
#ice_tree <- tree_freq %>% ice(data = dta_trn_sample,
                              #grid = grid_hp)
ice_rf_r<- rf_freq %>% ice_rf(data = dta_trn_sample,
                              grid = grid_hp)

#ice_gbm <- gbm_freq %>% ice(data = dta_trn_sample,
                            #grid = grid_hp)

#After some reshaping we plot these ICE curves with the PD effect on top, as in Figure 8 of the paper:


gridExtra::grid.arrange(
  ice_rf_r %>% reshape2::melt(id.vars = 'hp',
                              value.name = 'ice',
                              variable.name = 'observation') %>%
    dplyr::group_by(hp) %>% 
    dplyr::mutate(pd = mean(ice)) %>% 
    ggplot(aes(x = hp)) + 
    geom_line(aes(y = ice, group = observation), color = 'grey', alpha = 0.1) + 
    geom_line(aes(y = pd), size = 1, color = 'navy')
  

)


# Interaction Effect
str(dta)

interaction.plot(dta_trn$yrs.licensed,dta_trn$fuel.type ,dta_trn$clm.count,sum)




## Statistical performance.

# We fit quickly two trees to have a point of comparison

tree_freq <- rpart(formula = 
                     cbind(exposure,clm.count) ~
                     driver.age  + hp
                   + fuel.type + driver.gender + body.code + yrs.licensed,
                   data = dta_trn,
                   method = 'poisson', 
                   control = rpart.control(
                     maxdepth = 3,
                     cp = 0 ),
                   #parms = list(shrink = 10^5)
                   
)

tree_sev <- distRforest::rpart(
  formula =  clm.incurred ~
    driver.age  + hp
  + fuel.type + driver.gender + body.code + yrs.licensed,
  data = dta_trn_claims,
  weights = clm.count,
  method = 'gamma',
  control = rpart.control(cp = 3.7e-3, # cp in Table 3
                          minbucket = 0.01 * nrow(dta_trn_claims), # kappa in Table 1
                          xval = 0,
                          maxcompete = 0,
                          maxsurrogate = 0)
)

# Generic prediction function
predict_model <- function(object, newdata) UseMethod('predict_model')

# Prediction function for a regression tree
predict_model.rpart <- function(object, newdata) {
  predict(object, newdata, type = 'vector')
}

# Prediction function for a random forest
predict_model.rforest <- function(object, newdata) {
  predict(object, newdata)
}

# Prediction function for a GBM
predict_model.gbm <- function(object, newdata) {
  predict(object, newdata, n.trees = object$n.trees, type = 'response')
}



oos_pred <- tibble::tibble(
  tree_freq = tree_freq %>% predict_model(newdata = dta_tst),
  rf_freq = rf_freq %>% distRforest::predict.rforest(newdata = dta_tst),
  #gbm_freq = gbm_freq %>% predict_model(newdata = mtpl_tst),
  tree_sev = tree_sev %>% predict_model(newdata = dta_tst),
  rf_sev = rf_sev %>% distRforest::predict.rforest(newdata = dta_tst)
  #gbm_sev = gbm_sev %>% predict_model(newdata = mtpl_tst)
)


## Economic lift

#After comparing the ML models for frequency and severity, 
#we now turn to a comparison at the premium level. 
#We calculate the predicted premiums for the test data `mtpl_tst` 
#by multiplying the frequency and severity:


oos_pred <- oos_pred %>% dplyr::mutate(
  tree_prem = tree_freq * tree_sev, #wt: freq*sev = pure premium
  # rf_prem = rf_freq * rf_sev,
  rf_prem = rf_freq * rf_sev
)


oos_pred %>% dplyr::select(ends_with('_prem')) %>% 
  dplyr::summarise_all(~ sum(.x * dta_tst$exposure))


#We now focus on some model lift measures, which are introduced 
#and analyzed in Sections 5.1 and 5.2 of the paper. 
#To streamline the coding we add the observed target values from 
#the test data `mtpl_tst` to the predictions data:


oos_pred <- oos_pred %>% dplyr::mutate(
  nclaims = dta_tst$clm.count,
  expo = dta_tst$exposure,
  amount = dta_tst$clm.incurred
)

### Loss ratio lift
# The loss ratio lift is assessed by applying the following steps:
#   
#   + sort policies from smallest to largest relativity
# + bin the policies in groups of equal exposure
# + calculate the loss ratio in each bin using the benchmark premium


loss_ratio_lift <- function(data, bench, comp, ngroups) {
  
  # Calculate relativity and sort from small to large
  data %>% dplyr::mutate(r = get(paste0(comp, '_prem')) / get(paste0(bench, '_prem'))) %>% 
    dplyr::arrange(r) %>% 
    # Bin in groups of equal exposure
    dplyr::mutate(bin = cut(cumsum(expo),
                            breaks = sum(expo) * (0:ngroups) / ngroups,
                            labels = FALSE)) %>% 
    dplyr::group_by(bin) %>% 
    dplyr::mutate(r_lab = paste0('[', round(min(r), 2), ',', round(max(r), 2), ']')) %>% 
    # Calculate loss ratio per bin
    dplyr::summarise(r_lab = r_lab[1],
                     loss_ratio = sum(amount) / sum(get(paste0(bench, '_prem'))),
                     sum_expo = sum(expo))
  
}


lrl_rf_tree <- oos_pred %>% loss_ratio_lift(bench = 'tree',
                                             comp = 'rf',
                                             ngroups = 5)
lrl_tree_rf <- oos_pred %>% loss_ratio_lift(bench = 'rf',
                                             comp = 'tree',
                                             ngroups = 5)


gridExtra::grid.arrange(
  lrl_rf_tree %>% ggplot(aes(x = r_lab, y = loss_ratio)) +
    geom_bar(stat = 'identity') +
    ggtitle('comp: gbm / bench: tree'),
  
  lrl_tree_rf %>% ggplot(aes(x = r_lab, y = loss_ratio)) +
    geom_bar(stat = 'identity') +
    ggtitle('comp: tree / bench: gbm')
  
  #ncol = 2
)


### Double lift
#The double lift is assessed by applying the following steps:

#   + sort policies from smallest to largest relativity
# + bin the policies in groups of equal exposure
# + calculate the average loss amount and average premiums (comp & bench) in each bin
# + calculate the percentage error of premium (comp & bench) to loss in each bin


double_lift <- function(data, bench, comp, ngroups) {
  
  # Calculate relativity and sort from small to large
  data %>% dplyr::mutate(r = get(paste0(comp, '_prem')) / get(paste0(bench, '_prem'))) %>% 
    dplyr::arrange(r) %>% 
    # Bin in groups of equal exposure
    dplyr::mutate(bin = cut(cumsum(expo),
                            breaks = sum(expo) * (0:ngroups) / ngroups,
                            labels = FALSE)) %>% 
    dplyr::group_by(bin) %>% 
    dplyr::mutate(r_lab = paste0('[', round(min(r), 2), ',', round(max(r), 2), ']')) %>% 
    # Calculate percentage errors for both tariffs
    dplyr::summarise(r_lab = r_lab[1],
                     error_comp = mean(get(paste0(comp, '_prem'))) / mean(amount) - 1,
                     error_bench = mean(get(paste0(bench, '_prem'))) / mean(amount) - 1,
                     sum_expo = sum(expo))
  
}



dbl_rf_tree <- oos_pred %>% double_lift(bench = 'tree',
                                         comp = 'rf',
                                         ngroups = 5)
dbl_rf_tree



dbl_rf_tree %>% reshape2::melt(id.vars = c('r_lab', 'bin' , 'sum_expo'),
                                value.name = 'perc_err',
                                variable.name = 'tariff') %>% 
  ggplot(aes(x = r_lab, y = perc_err)) +
  geom_line(aes(group = tariff, colour = tariff))



### Gini index

#The last measure for economic lift that we analyze is the Gini index 
#obtained from an ordered Lorenz curve. The function `gini()` from the `cplm` package allows to calculate Gini indices for competing models. The mini-max strategy selects the GBM as the model that is least vulnerable to alternative models:


library(cplm)
gini(loss = 'amount',
     score = paste0(c('tree',  'rf'), '_prem'),
     data = as.data.frame(oos_pred))


#We can program the mini-max strategy explicitly as follows, 
#which gives the ranking `gbm > rf > tree`:


gini(loss = 'amount',
     score = paste0(c('tree', 'rf'), '_prem'),
     data = as.data.frame(oos_pred)) %>% 
  slot('gini') %>% 
  as.data.frame() %>% 
  dplyr::mutate(max_gini = pmax(tree_prem, rf_prem)) %>% 
  dplyr::mutate(bench = c('tree', 'rf')) %>% 
  dplyr::arrange(max_gini)






# https://statisticsglobe.com/r-error-usemethod-no-applicable-method-for-predict

####Crunched Residual Plot Funtion
res.plot.fn <- function(observed,fitted,model) {
  obs.fit.train<-cbind(observed,fitted)
  #order observations from smallest to largest predicted value
  obs.fit.train.sorted<-obs.fit.train[order(fitted),]
  res<-obs.fit.train.sorted[,2]-obs.fit.train.sorted[,1] #fitted-observed
  #Group residuals in to 500 buckets
  size<-length(res)/300
  g<-factor(round(size*c(1:300)))
  crunched.res<-lapply(split(res,g),mean)
  crunched.fitted<-lapply(split(obs.fit.train.sorted[,2],g),mean)
  plot(crunched.fitted,crunched.res)
  title(main=paste("Crunched residual plot for",model))
  #max(unlist(crunched.fitted))
}

# ggplot(VehCdt.expo,aes(x=Group.1,y=x))+geom_bar(stat="identity",fill=rgb(0.1,0.4,0.5,0.7))+
#   labs(x="Vehicle Condtion", y="Exposure")+
# ggplot(data=df, aes(x=dose, y=len, group=1)) +
#   geom_line(linetype = "dashed")+
#   geom_point(color="red")

####Relativity Plot
# Show the trend of the coefficients with respect to the base level
# df: dataframe with exposrues aggregated by the specified categorical varaible
# coeff: coefficient from the fitted model
# The dataset used to get df and fit glm is the same one.
relativity.plot<-function(df,coeff,predictor,IsPlotProportional){
  coeff<-exp(coeff)
  par(mar=c(5,4,4,6)+0.1)
  c <- df$x/sum(df$x)
  if (!IsPlotProportional) {
    barplot(height = df$x, col=rgb(0.2,0.4,0.6,0.6), ylim = c(0,max(df$x)*1.5),names.arg = df$Group.1, ylab = "Expo Count",xlab=predictor)
  } else {
    barplot(height = c, col=rgb(0.2,0.4,0.6,0.6), ylim = c(0,max(c)*1.5),names.arg = df$Group.1, ylab = "Expo Prop'n",xlab=predictor)
  }
  par(new=TRUE)
  plot(c(1, coeff),type="b", axes= FALSE, xlab ="",ylab = "", ylim=c(as.integer(min(coeff,1)),as.integer(max(coeff))+1), main="Claim Count")
}


####Lift plot
# predicted: vector of predicted values
# observed: vector of observed values
# bins: number of bins to split the data
# title: title of graph
# y.label: y-axis label; whats being being plotted
# IsPlotProportional: TREU or FALSE
lift.plot<-function(predicted, observed, exposure,bins, title, y.label,IsPlotProportional){
  u<-cbind("predicted"=predicted, "obs"=observed, "expo"=exposure)
  u<-na.omit(u)
  u<-cbind(u,"SortOrder"=u[,1]/u[,3])
  u.sorted<-u[order(u[,4]),]
  size<-length(u.sorted[,"predicted"])/bins
  g<-factor(round(size*c(1:bins)))
  
  crunched.pred<-tapply(u.sorted[,"predicted"], (seq_along(u.sorted[,"predicted"])-1) %/% size, mean)
  crunched.obs<-tapply(u.sorted[,"obs"], (seq_along(u.sorted[,"obs"])-1) %/% size, mean)
  expo<-tapply(u.sorted[,"expo"], (seq_along(u.sorted[,"expo"])-1) %/% size, mean)
  
  if (!IsPlotProportional) {
    barplot(height = expo, col=rgb(0.2,0.4,0.6,0.6), ylim = c(0,max(expo)),names.arg = c(1:bins), ylab = "Expo Count")
  } else {
    barplot(height = expo/sum(expo), col=rgb(0.2,0.4,0.6,0.6), ylim = c(0,max(expo/sum(expo))*1.25),names.arg = c(1:bins), ylab = "Expo Prop'n")
  }
  par(new=TRUE)
  
  v<-rep(mean(u[,"obs"]),bins)
  plot(c(1:bins),v,type="l",col="blue",ylim=c(0,max(crunched.pred,crunched.obs,na.rm=TRUE)),axes=FALSE,xlab="",ylab="")
  lines(c(1:bins), crunched.pred,type="o",col="red")
  lines(c(1:bins), crunched.obs,type="o",col="blue")
  x<-round(max(crunched.pred,crunched.obs,na.rm=TRUE)/7,digits=2)
  axis(side=4,at=seq(0,x*7.5,by=x))
  mtext(y.label, side=4, line =2)
  title(main=paste(title))
  legend("top",c("Predicted","Observed"),col=c("red","blue"),lty=1, cex=0.8)
  
}

getCurrentFileLocation <-  function()
{
  this_file <- commandArgs() %>% 
    tibble::enframe(name = NULL) %>%
    tidyr::separate(col=value, into=c("key", "value"), sep="=", fill='right') %>%
    dplyr::filter(key == "--file") %>%
    dplyr::pull(value)
  if (length(this_file)==0)
  {
    this_file <- rstudioapi::getSourceEditorContext()$path
  }
  return(dirname(this_file))
}

str(dta_tst)

# Lift Plot
#lift.plot(pred4_Cxl_train,train_nonAgg[,"ClaimCnt"],train_nonAgg[,"Expo"],20,"Cancellation Count Lift Chart - Train_poisson", "Avg Claim Count",TRUE)
lift.plot(results_fit_rf,dta_tst[,"clm.count"],dta_tst[,"exposure"],20,"Cancellation Count Lift Chart - Test_poisson", "Avg Claim Count",TRUE)

#lift.plot(pred5_Cxl_train,train_nonAgg[,"ClaimCnt"],train_nonAgg[,"Expo"],20,"Cancellation Count Lift Chart - Train_quasi-poisson", "Avg Cancellation Count",TRUE)
lift.plot(results_fit_rf,dta_tst[,"dta_tst"],dta_tst[,"exposure"],20,"Cancellation Count Lift Chart - Test_quasi-poisson", "Avg Cancellation Count",TRUE)


# Tentative with lift.chart
# https://www.rdocumentation.org/packages/BCA/versions/0.9-3/topics/lift.chart

??lift.chart

# https://modeloriented.github.io/auditor/reference/plot_lift.html

model1 <-glm(clm.count ~ driver.age + hp, family = poisson, offset=log(exposure),
             data=dta_trn)


model2 <-glm(clm.count ~ driver.age+ driver.gender + hp, family = poisson, offset=log(exposure),
             data=dta_trn)

install.packages('BCA')

lift.chart(c("model1", "model2"), data=dta_tst, targLevel="Yes",
           trueResp=0.01, type="cumulative", sub="Validation")
